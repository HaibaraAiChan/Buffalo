main start at this time 1733040443.27914
-----------------------------------------before load data 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.3560791015625 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

epoch  0
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.131455659866333
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0003521442413330078
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01208353042602539
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1320188045501709
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.5220425128936768
self.buckets_partition() spend  sec:  0.1441197395324707
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 5.205390930175781
----------------------------------------after train
 Nvidia-smi: 22.95068359375 GB
    Memory Allocated: 0.5931186676025391  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  1
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13517260551452637
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0003685951232910156
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013177156448364258
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13569951057434082
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.537830114364624
self.buckets_partition() spend  sec:  0.1488969326019287
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.887031078338623
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5925149917602539  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  2
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13433241844177246
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005719661712646484
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013056516647338867
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13506603240966797
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.5010006427764893
self.buckets_partition() spend  sec:  0.1482558250427246
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.588084697723389
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5924191474914551  GigaBytes
Max Memory Allocated: 21.224058151245117  GigaBytes

epoch  3
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13554072380065918
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0007207393646240234
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013216257095336914
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13642549514770508
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4593005180358887
self.buckets_partition() spend  sec:  0.14966797828674316
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.2999091148376465
----------------------------------------after train
 Nvidia-smi: 22.97802734375 GB
    Memory Allocated: 0.5923662185668945  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  4
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13401269912719727
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0007026195526123047
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011639833450317383
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13488435745239258
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.431993007659912
self.buckets_partition() spend  sec:  0.1465451717376709
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 4.042307376861572
----------------------------------------after train
 Nvidia-smi: 23.00146484375 GB
    Memory Allocated: 0.5940918922424316  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  5
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13866281509399414
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.001111745834350586
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014527559280395508
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1401348114013672
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.498112916946411
self.buckets_partition() spend  sec:  0.15468668937683105
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.804751396179199
----------------------------------------after train
 Nvidia-smi: 23.35888671875 GB
    Memory Allocated: 0.5962615013122559  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  6
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13731932640075684
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0009241104125976562
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01194906234741211
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13843369483947754
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.455080270767212
self.buckets_partition() spend  sec:  0.1504058837890625
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.616945743560791
----------------------------------------after train
 Nvidia-smi: 23.39208984375 GB
    Memory Allocated: 0.5910611152648926  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  7
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.31746816635131836
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005395412445068359
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.014578819274902344
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.31818103790283203
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.633122444152832
self.buckets_partition() spend  sec:  0.3327822685241699
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.485229015350342
----------------------------------------after train
 Nvidia-smi: 23.39404296875 GB
    Memory Allocated: 0.5918097496032715  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  8
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.15154647827148438
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0010771751403808594
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011337757110595703
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.15277934074401855
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.750243663787842
self.buckets_partition() spend  sec:  0.1641397476196289
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.376310110092163
----------------------------------------after train
 Nvidia-smi: 23.39404296875 GB
    Memory Allocated: 0.5965161323547363  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  9
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.13827276229858398
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006415843963623047
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013615846633911133
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.13912367820739746
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4756782054901123
self.buckets_partition() spend  sec:  0.15276122093200684
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.2417328357696533
----------------------------------------after train
 Nvidia-smi: 23.39404296875 GB
    Memory Allocated: 0.5934982299804688  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  10
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.15004944801330566
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0010902881622314453
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010978460311889648
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1512751579284668
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.706578493118286
self.buckets_partition() spend  sec:  0.1622757911682129
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 3.0979013442993164
----------------------------------------after train
 Nvidia-smi: 23.39404296875 GB
    Memory Allocated: 0.5919413566589355  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  11
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.15446996688842773
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0010502338409423828
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013349771499633789
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.15573573112487793
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.7285990715026855
self.buckets_partition() spend  sec:  0.16910910606384277
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.9544131755828857
----------------------------------------after train
 Nvidia-smi: 23.39404296875 GB
    Memory Allocated: 0.6013007164001465  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  12
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.17746329307556152
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006401538848876953
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010690689086914062
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.17829203605651855
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.7078351974487305
self.buckets_partition() spend  sec:  0.18901920318603516
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.840362071990967
----------------------------------------after train
 Nvidia-smi: 22.06591796875 GB
    Memory Allocated: 0.596318244934082  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  13
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.1476125717163086
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005645751953125
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.012799739837646484
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1483151912689209
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.678520441055298
self.buckets_partition() spend  sec:  0.16113543510437012
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.744246482849121
----------------------------------------after train
 Nvidia-smi: 22.09912109375 GB
    Memory Allocated: 0.594810962677002  GigaBytes
Max Memory Allocated: 21.228174209594727  GigaBytes

epoch  14
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.1479053497314453
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0006551742553710938
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.0108489990234375
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.14868974685668945
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.6634392738342285
self.buckets_partition() spend  sec:  0.15955758094787598
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.6565232276916504
----------------------------------------after train
 Nvidia-smi: 22.09912109375 GB
    Memory Allocated: 0.5961380004882812  GigaBytes
Max Memory Allocated: 21.228796005249023  GigaBytes

epoch  15
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.14866948127746582
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005159378051757812
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010245800018310547
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.14931201934814453
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.6719515323638916
self.buckets_partition() spend  sec:  0.1595761775970459
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.577582836151123
----------------------------------------after train
 Nvidia-smi: 22.09912109375 GB
    Memory Allocated: 0.5915389060974121  GigaBytes
Max Memory Allocated: 21.23391628265381  GigaBytes

epoch  16
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.15226960182189941
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005147457122802734
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.01028585433959961
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.15293097496032715
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.6940081119537354
self.buckets_partition() spend  sec:  0.1632382869720459
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.4829721450805664
----------------------------------------after train
 Nvidia-smi: 23.21044921875 GB
    Memory Allocated: 0.590672492980957  GigaBytes
Max Memory Allocated: 21.23391628265381  GigaBytes

epoch  17
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.14705681800842285
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.001043558120727539
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.013835430145263672
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1482374668121338
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.692988634109497
self.buckets_partition() spend  sec:  0.1620938777923584
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.387866735458374
----------------------------------------after train
 Nvidia-smi: 23.21240234375 GB
    Memory Allocated: 0.5947017669677734  GigaBytes
Max Memory Allocated: 21.23391628265381  GigaBytes

epoch  18
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.1474609375
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0005848407745361328
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.010979652404785156
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1482081413269043
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.6650290489196777
self.buckets_partition() spend  sec:  0.1592099666595459
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.2862625122070312
----------------------------------------after train
 Nvidia-smi: 23.21240234375 GB
    Memory Allocated: 0.5982723236083984  GigaBytes
Max Memory Allocated: 21.23391628265381  GigaBytes

epoch  19
the output layer 
self.num_batch (get_in_degree_bucketing) 12
get_in_degree_bucketing dst global nid length 196571
len(bkt)  173
len(bkt)  221
len(bkt)  374
len(bkt)  456
len(bkt)  445
len(bkt)  550
len(bkt)  655
len(bkt)  512
len(bkt)  576
len(bkt)  640
len(bkt)  624
len(bkt)  583
len(bkt)  615
len(bkt)  695
len(bkt)  673
len(bkt)  614
len(bkt)  556
len(bkt)  604
len(bkt)  584
len(bkt)  572
len(bkt)  586
len(bkt)  592
len(bkt)  648
len(bkt)  645
len(bkt)  183378
total indegree bucketing result ,  196571
the number of total output nodes match :) 
local nids of zero in-degree  []
bucket partitioner: bkt_dst_nodes_list_local length  25
---||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||-----||--
self.num_batch,  12
type of fanout_dst_nids  <class 'torch.Tensor'>
sum(estimated_mem)
27.023624836713726
24
the last batch value is  1464
G_BUCKET_ID_list [[11, 3, 2], [19, 13, 0], [23, 8], [14, 9, 7], [17, 10, 4], [6, 5, 1], [16, 12], [22], [21], [20], [18], [15]]
G_BUCKET_ID_list length 12
backpack scheduling spend  0.14293336868286133
len(g_bucket_nids_list)  12
len(local_split_batches_nid_list)  12
current group_mem  1.403347350375729
current group_mem  3.001967961271789
current group_mem  3.0000069573568977
current group_mem  3.0006915325832333
current group_mem  2.9975327611562568
current group_mem  1.0749997896799088
current group_mem  2.939728300182595
current group_mem  2.232189497508864
current group_mem  2.1946883605045633
current group_mem  1.920127067184496
current group_mem  1.793769060001223
current group_mem  1.4645761989081698
batches output list generation spend  0.0009181499481201172
self.weights_list  [0.08493114447197196, 0.08506849942260049, 0.08395439815639133, 0.0870270792741554, 0.08625382177432073, 0.0849972783370894, 0.08370003713670887, 0.08103942087083038, 0.08075453652878603, 0.08072401320642414, 0.08071383876563684, 0.08083593205508442]
bkt_dst_nodes_list = self.get_in_degree_bucketing() spend:  0.011638641357421875
self.gen_batches_seeds_list(bkt_dst_nodes_list_local) spend  0.1440439224243164
self.has_zero_indegree_seeds  False
num_output  196571
self.output_nids  196571
output nodes length match
global output equals  True
partition total batch output list spend :  2.4892349243164062
self.buckets_partition() spend  sec:  0.15570759773254395
step  0
step  1
step  2
step  3
step  4
step  5
step  6
step  7
step  8
step  9
step  10
step  11
----------------------------------------------------------pseudo_mini_loss sum 2.1992878913879395
----------------------------------------after train
 Nvidia-smi: 23.21240234375 GB
    Memory Allocated: 0.5930790901184082  GigaBytes
Max Memory Allocated: 21.23391628265381  GigaBytes

epoch_time_list  [24.3455228805542, 20.800288200378418, 20.326370000839233, 20.821074724197388, 23.452829360961914, 22.887423276901245, 21.097605228424072, 23.172013759613037, 23.250073194503784, 21.930370092391968, 23.69821310043335, 21.00528120994568, 21.74357032775879, 20.309301137924194, 20.31486463546753, 20.145570516586304, 20.90327477455139, 21.10842514038086, 21.408928632736206, 22.856752395629883]

loading_time list   [0.5617384910583496, 0.5963363647460938, 0.5305864810943604, 0.48495936393737793, 0.4626772403717041, 0.4379558563232422, 0.36722493171691895, 0.3643920421600342, 0.6039350032806396, 0.4552121162414551, 0.5646786689758301, 0.4246363639831543, 0.5141720771789551, 0.44546985626220703, 0.5297427177429199, 0.4442787170410156, 0.39757823944091797, 0.5779714584350586, 0.4597136974334717, 0.46503424644470215]

 data loader gen time  [15.14038610458374, 14.155412912368774, 14.16094446182251, 14.68137001991272, 17.1145658493042, 16.929500341415405, 15.290993213653564, 17.372832536697388, 17.087503671646118, 16.178184747695923, 17.68924832344055, 15.289595365524292, 15.224593162536621, 14.526306629180908, 14.43929934501648, 14.23808240890503, 15.031697273254395, 15.194952726364136, 15.410674810409546, 16.90429377555847]
	---backpack schedule time  [2.599118232727051, 2.627551555633545, 2.569478750228882, 2.537264108657837, 2.5194461345672607, 2.5840609073638916, 2.524758815765381, 2.6981661319732666, 2.8366241455078125, 2.539208173751831, 2.7726755142211914, 2.8011255264282227, 2.7872157096862793, 2.732452630996704, 2.723971366882324, 2.7360363006591797, 2.7552459239959717, 2.746819257736206, 2.7364070415496826, 2.5516138076782227]
	---connection_check_time_list  [7.409886360168457, 6.586362838745117, 6.664896011352539, 6.928681135177612, 9.6352379322052, 9.253840208053589, 8.19325041770935, 9.392704486846924, 9.485768795013428, 8.498464584350586, 9.862405061721802, 7.337725400924683, 7.51912260055542, 6.812524795532227, 6.90325927734375, 6.861800909042358, 7.4719078540802, 7.362338304519653, 7.355008363723755, 8.92104697227478]
	---block_gen_time_list  [4.444103717803955, 4.247788429260254, 4.248614311218262, 4.550835371017456, 4.303870677947998, 4.368146896362305, 3.9287238121032715, 4.567729473114014, 4.06751275062561, 4.444621562957764, 4.306977987289429, 4.412280559539795, 4.2018349170684814, 4.242521047592163, 4.089462518692017, 3.920427083969116, 4.114117383956909, 4.367228269577026, 4.592491626739502, 4.787941932678223]
training time  [8.642744064331055, 6.044723272323608, 5.630282878875732, 5.649746894836426, 5.870722055435181, 5.514688968658447, 5.434278249740601, 5.429443597793579, 5.550482511520386, 5.2913477420806885, 5.436049461364746, 5.282788991928101, 5.997396945953369, 5.330283880233765, 5.338940858840942, 5.456129789352417, 5.466846227645874, 5.328323602676392, 5.531236171722412, 5.480285406112671]
---feature block loading time  [3.225531816482544, 3.3963563442230225, 3.331120014190674, 3.3020548820495605, 3.2363052368164062, 3.1355443000793457, 3.069326639175415, 3.0061657428741455, 3.2108354568481445, 2.942138195037842, 3.0553054809570312, 2.9140419960021973, 3.053227186203003, 2.950488805770874, 2.9687612056732178, 3.1219441890716553, 3.063129186630249, 2.963818311691284, 3.221222400665283, 3.1916890144348145]


epoch_time avg   21.830281049013138
loading_time avg   0.46966707706451416
 data loader gen time avg 15.87014526128769
	---backpack schedule time avg 2.6903642117977142
	---connection_check_time avg  8.179150372743607
	---block_gen_time avg  4.294743031263351
training time  5.483702778816223
---feature block loading time  3.0689964592456818
pure train time per /epoch  [5.414289951324463, 2.530263900756836, 2.169646978378296, 2.222761631011963, 2.5096373558044434, 2.2523181438446045, 2.238239049911499, 2.2962558269500732, 2.20900821685791, 2.2231080532073975, 2.2602603435516357, 2.23652720451355, 2.8150746822357178, 2.2509710788726807, 2.2403972148895264, 2.202831745147705, 2.2753961086273193, 2.2330336570739746, 2.1860713958740234, 2.156358003616333]
pure train time average  2.282838218352374
